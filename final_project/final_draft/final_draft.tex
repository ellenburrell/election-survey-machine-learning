% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Final Project},
  pdfauthor={Ellen Burrell: PSTAT 131},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Final Project}
\author{Ellen Burrell: PSTAT 131}
\date{}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Libraries imported}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(tidymodels)}
\FunctionTok{library}\NormalTok{(ISLR)}
\FunctionTok{library}\NormalTok{(rpart.plot)}
\FunctionTok{library}\NormalTok{(vip)}
\FunctionTok{library}\NormalTok{(janitor)}
\FunctionTok{library}\NormalTok{(randomForest)}
\FunctionTok{library}\NormalTok{(xgboost)}
\FunctionTok{library}\NormalTok{(here)}
\FunctionTok{library}\NormalTok{(tune)}
\FunctionTok{library}\NormalTok{(parsnip)}
\end{Highlighting}
\end{Shaded}

\hypertarget{introduction}{%
\subsection{INTRODUCTION}\label{introduction}}

American Politics are becoming increasingly partisan at an alarming
rate. While the United States has two main political parties, the
division among primary voters for each party is increasing. According to
a study done by the Pew Research Center, ``Across 30 political values --
encompassing attitudes about guns, race, immigration, foreign policy and
other realms -- the average partisan gap is 39 percentage points''
between the two parties. The average difference for other grouping
factors such as Education, Age, or Gender were around 6-10 percentage
points (Nadeem). From this data, we can conclude that the political
values that each party represents must be antithetical to have created
such a sharp division.

If given such data, could we predict how a person voted in the 2016
presidential election? Would someone's party affiliation or political
values be more important in determining who they voted for?

In this project we look at the data from `The Views of the Electorate
Research (VOTER) Survey' conducted by YouGov. Although we will be
looking at data from the 2016 election, the respondents were originally
interviewed in 2011, 2012, and then in 2016 for a third time. The entire
dataset contains responses by 8,000 adults (age 18+) with internet
access on 668 questions.

The questions in this survey are VERY comprehensive.

To begin, the survey asks who one voted for in the 2016 election. Then,
some of the questions ask about opinions on a specific person.

\textbf{``Do you have a favorable or an unfavorable opinion of the
following people? BARACK OBAMA''}

Or about honesty in US Elections\ldots{}

\textbf{``How confident are you that the votes in the 2016 election
across the country were accurately counted?''}

Or about general opinions.

\textbf{``Which do you think is more important for a child to have?
Curiosity OR Good manners?''}

And some biographical questions such as

\textbf{``Have you smoked at least 100 cigarettes in your entire
life?''}

Some of the most valuable data comes from a section labeled ``Feeling
Thermometer'', where the survey asks respondents to rate various groups
on a scale from 0-100. The question is framed as

\textbf{``We'd like to get your feelings toward some groups who are in
the news these days. Ratings between 50 degrees and 100 degrees mean
that you feel favorable and warm toward the group. Ratings between 0
degrees and 50 degrees mean that you don't feel favorable toward the
group and that you don't care too much for that group. You would rate
the group at the 50 degree mark if you don't feel particularly warm or
cold toward the group. If we come to a group who you don't recognize,
you don't need to rate that group. Click on the thermometer to give a
rating.''}

The survey then frames this question about each upcoming group
individually -
`Blacks',`Whites',`Hispanics',`Asians',`Muslims',`Jews',`Christians',`Feminists',
`Immigrants',`Black Lives Matter', `Wall Street Bankers', `Gays and
Lesbians', `Labor Unions', `Police Officers', and the `The alt-right
movement'.

For more information on the Survey, look at the citations at the bottom
of this report.

\hypertarget{variable-selection-and-data-cleaning}{%
\subsection{Variable Selection and Data
Cleaning}\label{variable-selection-and-data-cleaning}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{setwd}\NormalTok{(}\StringTok{"\textasciitilde{}/pstat/131/pstat131/final\_project\_edited"}\NormalTok{)}
\NormalTok{VOTER\_Survey\_December16\_Release1 }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"archive/VOTER\_Survey\_December16\_Release1.csv"}\NormalTok{)}
\CommentTok{\# only taking data from 2016 survey respondent }
\NormalTok{cleaned\_data\_2016 }\OtherTok{\textless{}{-}}\NormalTok{ VOTER\_Survey\_December16\_Release1 }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\FunctionTok{ends\_with}\NormalTok{(}\StringTok{"2016"}\NormalTok{))}
\CommentTok{\#dim(cleaned\_data\_2016)}
\end{Highlighting}
\end{Shaded}

By only looking at the questions asked in 2016, we cut down our
variables from 668 to 272.

Although it would be interesting to analyze, I didn't think it would be
realistic or possible to use all 272 variables. Therefore I choose 25
questions that I found the most interesting. These included all of the
feeling thermometer questions, a question on smoking, drinking,
religion, opinions about the accuracy of ballot counting, one's
political affiliation, and ideology. To see the exact breakdown of
questions, I invite you to look at the survey\_codebook.txt within the
data file.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{more\_cleaned\_data\_2016 }\OtherTok{\textless{}{-}}\NormalTok{ VOTER\_Survey\_December16\_Release1 }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\FunctionTok{ends\_with}\NormalTok{(}\StringTok{"2016"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\FunctionTok{starts\_with}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"izip\_2016"}\NormalTok{,}\StringTok{"presvote16post\_"}\NormalTok{,}\StringTok{"ft"}\NormalTok{,}\StringTok{"accurately\_counted2"}\NormalTok{,}\StringTok{"alcohol"}\NormalTok{,}\StringTok{"smoke100"}\NormalTok{,}\StringTok{"pid7"}\NormalTok{,}\StringTok{"ideo"}\NormalTok{,}\StringTok{"pew\_religimp"}\NormalTok{,}\StringTok{"starttime"}\NormalTok{,}\StringTok{"endtime"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\StringTok{"presvote16post\_t\_2016"}\NormalTok{,}\StringTok{"presvote16post\_rnd\_2016"}\NormalTok{))}
\CommentTok{\#dim(more\_cleaned\_data\_2016)}
\end{Highlighting}
\end{Shaded}

From here I had some importing cleaning to do of the variables. First of
all, all of the answers to the surveys were in strings, so I had to
convert all of the integers within strings to numeric values. This was
not easy, because some of feeling thermometer questions had strings
before the numbers as shown below.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 0 - Unfavorable feeling                       1                      10 
##                       8                       5                      11 
## 100 - Favorable feeling                      11                      12 
##                     879                      16                       6 
##                      14                      15                      16 
##                       4                       4                       3 
##                      17                      18                      19 
##                       3                       2                       5 
##                       2                      20                      21 
##                       6                      10                       8 
##                      22                      23                      24 
##                       5                       4                       6 
## 25 -Unfavorable feeling                      26                      27 
##                      25                      11                       7 
##                      28                      29                       3 
##                      14                       4                       6 
##                      30                      31                      32 
##                      20                      29                       6 
##                      33                      34                      35 
##                       6                       9                      13 
##                      36                      37                      38 
##                      13                       9                       7 
##                      39                       4                      40 
##                      15                       5                      37 
##                      41                      42                      43 
##                      40                      13                      13 
##                      44                      45                      46 
##                      21                      25                      15 
##                      47                      48                      49 
##                      25                      30                      69 
##                       5  50 - No feeling at all                      51 
##                       6                     750                     244 
##                      52                      53                      54 
##                     101                      87                      32 
##                      55                      56                      57 
##                      46                      49                      30 
##                      58                      59                       6 
##                      24                      54                       8 
##                      60                      61                      62 
##                     115                      61                      33 
##                      63                      64                      65 
##                      48                      26                      52 
##                      66                      67                      68 
##                      61                      30                      40 
##                      69                       7                      70 
##                      97                       2                     152 
##                      71                      72                      73 
##                      86                      80                      43 
##                      74  75 - Favorable feeling                      76 
##                      70                     285                     127 
##                      77                      78                      79 
##                      89                     137                     188 
##                       8                      80                      81 
##                       1                     370                     220 
##                      82                      83                      84 
##                      57                      64                      97 
##                      85                      86                      87 
##                     123                      81                      59 
##                      88                      89                       9 
##                      94                     137                       5 
##                      90                      91                      92 
##                     372                     208                      82 
##                      93                      94                      95 
##                      92                     126                     175 
##                      96                      97                      98 
##                     120                     138                     152 
##                      99              Don't know 
##                     282                      97
\end{verbatim}

Therefore I had to re-code all of those values as strings, and then
convert them to integers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016 }\OtherTok{\textless{}{-}} \FunctionTok{recode}\NormalTok{(more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016, }\StringTok{"100 {-} Favorable feeling"} \OtherTok{=} \StringTok{"100"}\NormalTok{)}
\NormalTok{more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016 }\OtherTok{\textless{}{-}} \FunctionTok{recode}\NormalTok{(more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016, }\StringTok{"75 {-} Favorable feeling"} \OtherTok{=} \StringTok{"75"}\NormalTok{)}
\NormalTok{more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016 }\OtherTok{\textless{}{-}} \FunctionTok{recode}\NormalTok{(more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016, }\StringTok{"25 {-}Unfavorable feeling"} \OtherTok{=} \StringTok{"25"}\NormalTok{)}
\NormalTok{more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016 }\OtherTok{\textless{}{-}} \FunctionTok{recode}\NormalTok{(more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016, }\StringTok{"50 {-} No feeling at all"} \OtherTok{=} \StringTok{"50"}\NormalTok{)}
\NormalTok{more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016 }\OtherTok{\textless{}{-}} \FunctionTok{recode}\NormalTok{(more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016, }\StringTok{"0 {-} Unfavorable feeling"} \OtherTok{=} \StringTok{"0"}\NormalTok{)}
\NormalTok{more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016 }\OtherTok{\textless{}{-}} \FunctionTok{recode}\NormalTok{(more\_cleaned\_data\_2016}\SpecialCharTok{$}\NormalTok{ft\_white\_2016, }\StringTok{"Don\textquotesingle{}t know"} \OtherTok{=} \StringTok{"4000"}\NormalTok{) }\CommentTok{\#coded as an outlier so I rememeber to change it later}

\CommentTok{\# changing the strings to integers}
\NormalTok{more\_cleaned\_data\_2016 }\OtherTok{\textless{}{-}}\NormalTok{ more\_cleaned\_data\_2016 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ft\_white\_2016 =} \FunctionTok{as.numeric}\NormalTok{(ft\_white\_2016))}
\CommentTok{\#is.numeric(more\_cleaned\_data\_2016$ft\_white\_2016) \#TRUE}
\end{Highlighting}
\end{Shaded}

I cleaned all of the feeling thermometer questions in this matter, and
had to decide what to do about answers such as ``Don't Know'' and values
unanswered (NA). While I experimented with different approaches to this
problem, I ultimately decided that the best solution was to code any
answers of ``Don't Know'' as NA, and then remove all un-answered
observations. This was a tough call to make, because I didn't want to
lose any data or statistic power. However, the goal of this project for
me was to look at opinions of respondents and who they subsequently
voted for, so I interpreted someone as not answering or answering
``Don't Know'' as not very clear opinions. Additionally, I didn't want
to make any assumptions for the respondent if they didn't respond, so I
decide to not include the rest of their data.

To see more specifics of my data cleaning, I invite people to look at
the cleaning folder.

\hypertarget{explatory-data-analysis-eda}{%
\subsection{EXPLATORY DATA ANALYSIS
(EDA)}\label{explatory-data-analysis-eda}}

Here I am reading in the cleaned data file, and factoring all of the
variables that are non-numeric.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# reading in our data }
\NormalTok{survey }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/no\_na.csv"}\NormalTok{)}
\CommentTok{\# factoring data}
\NormalTok{survey }\OtherTok{\textless{}{-}}\NormalTok{ survey }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{accurately\_counted2\_2016 =} \FunctionTok{factor}\NormalTok{(accurately\_counted2\_2016, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Not at all confident"}\NormalTok{,}\StringTok{"Not too confident"}\NormalTok{,}
                                                                                \StringTok{"Somewhat confident"}\NormalTok{,}\StringTok{"Very confident"}\NormalTok{),}\AttributeTok{exclude =} \ConstantTok{NULL}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{alcohol\_2016 =} \FunctionTok{factor}\NormalTok{(alcohol\_2016, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Yes"}\NormalTok{,}\StringTok{"No"}\NormalTok{),}\AttributeTok{exclude=}\ConstantTok{NULL}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{smoke100\_2016 =} \FunctionTok{factor}\NormalTok{(smoke100\_2016, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Yes"}\NormalTok{,}\StringTok{"No"}\NormalTok{),}\AttributeTok{exclude=}\ConstantTok{NULL}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pid7\_2016 =} \FunctionTok{factor}\NormalTok{(pid7\_2016)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ideo5\_2016 =} \FunctionTok{factor}\NormalTok{(ideo5\_2016, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Very liberal"}\NormalTok{,}\StringTok{"Liberal"}\NormalTok{,}\StringTok{"Not sure"}\NormalTok{,}\StringTok{"Moderate"}\NormalTok{,}\StringTok{"Conservative"}\NormalTok{,}\StringTok{"Very conservative"}\NormalTok{), }\AttributeTok{exclude =} \ConstantTok{NULL}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pew\_religimp\_2016 =} \FunctionTok{factor}\NormalTok{(pew\_religimp\_2016, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Not at all important"}\NormalTok{,}\StringTok{"Not too important"}\NormalTok{,}\StringTok{"Somewhat important"}\NormalTok{,}\StringTok{"Very important"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{presvote16post\_2016 =} \FunctionTok{factor}\NormalTok{(presvote16post\_2016))}
\end{Highlighting}
\end{Shaded}

Let's take a look at our outcome variable, presvote16post\_2016.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ survey, }\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{fill=}\NormalTok{presvote16post\_2016,}\AttributeTok{x =} \FunctionTok{reorder}\NormalTok{(}\FunctionTok{factor}\NormalTok{(presvote16post\_2016), presvote16post\_2016, }\ControlFlowTok{function}\NormalTok{(x) }\SpecialCharTok{{-}}\FunctionTok{length}\NormalTok{(x)))) }\SpecialCharTok{+} \FunctionTok{geom\_bar}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-7-1.pdf}

The survey has the most responses for Hilary Clinton and Donald Trump,
with only a small fraction representing responses for Evan McMullin, Did
not vote for President, Jill Stein, Other, and Gary Johnson.

Let's look at some plots with two different feeling thermometer scales
on each axis, with presidental vote as the color highlighting the
differences.

\textbf{Feeling thermometers for Police and Labor Unions}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(survey, }\FunctionTok{aes}\NormalTok{(ft\_police\_2016, ft\_unions\_2016, }\AttributeTok{colour =}\NormalTok{ presvote16post\_2016)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-8-1.pdf}

Here we see a large clustering of yellow dots in the lower right hand
corner, and a cluster of blue dots in the right upper most quadrant. It
seems as if the voters for Donald Trump tend to rank police officers
with a high rating and labor unions with a lower than 50 rating. Clinton
supporters tend to be more variable, but on average tend to rank police
officers pretty highly, as well as labor unions above 50 points.

\textbf{Feeling thermometers for BLM and Feminists}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(survey, }\FunctionTok{aes}\NormalTok{(ft\_blm\_2016, ft\_fem\_2016, }\AttributeTok{colour =}\NormalTok{ presvote16post\_2016)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-9-1.pdf}

This seems to be our most polarized graph, with one large yellow cluster
in the left bottom quadrant, and a strong blue cluster in the upper
right quadrant. People who voted for Hillary Clinton tend to rank
Feminists and BLM higher than those who voted for Trump. I also think
it's worthwhile to mention that the other nominees (Evan McMullin, Gary
Johnson, Hilary Clinton, Jill Stein, Other, Did not vote for President)
seem to be scattered throughout, with no real strong cluster noticeable.
We might be able to notice the purple dots (Jill Stein) following the
trend of blue towards the middle right, but it's not very clear.

\textbf{Feeling thermometers for Jews and Christians}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(survey, }\FunctionTok{aes}\NormalTok{(ft\_jew\_2016, ft\_christ\_2016, }\AttributeTok{colour =}\NormalTok{ presvote16post\_2016)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-10-1.pdf}

From this graph, we see a very interesting pattern. People who voted for
Hilary Clinton tended to cluster near the 50 mark and on wards for
ranking Jewish people, yet are very variable from 0-100 ranking
Christians. People who voted for Donald Trump cluster near the top right
hand quarter, ranking both Christians and Jews favorably.

Now, let's divide on political ideology.

\textbf{Ideology dividing feeling thermometer of feminist and BLM}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(survey, }\FunctionTok{aes}\NormalTok{(ft\_blm\_2016, ft\_fem\_2016, }\AttributeTok{colour =}\NormalTok{ ideo5\_2016)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-11-1.pdf}

When we divide on ideology, the results are not as clear. There seems to
be a small cluster of pink, purple, and blue in the bottom left corner,
which would depict moderate, conservative and very conservative as
ranking feminists and BLM low. There also seems to be a red and yellow
cluster in the top right corner, showing liberal and very liberal as
ranking feminists and BLM high. Also, there seems to be a long green
cluster around the 50 mark, depicting `Not sure' people as staying
around the halfway mark of ranking. However these results are not as
polarized, and for the most part the colors are scattered throughout.

\textbf{Ideology dividing feeling thermometer of Asians and Hispanics}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(survey, }\FunctionTok{aes}\NormalTok{(ft\_asian\_2016, ft\_hisp\_2016, }\AttributeTok{colour =}\NormalTok{ ideo5\_2016)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-12-1.pdf}

From this plot, we can see a huge cluster of all ideologies in the upper
right corner, depicting a general positive feeling thermometers for
`Hispanics' and `Asians'. There doesn't seem to be any huge polarization
within ideology for these feeling thermometers.

For the next two plots, let's keep the feeling thermometer for `the
alt-right movement' on the y-axis, and look at the differences in plots
for feeling thermometer of `Christians' and `Muslims'.

\textbf{Feeling thermometers for Alt-right and Christians}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(survey, }\FunctionTok{aes}\NormalTok{(ft\_christ\_2016, ft\_altright\_2016, }\AttributeTok{colour =}\NormalTok{ presvote16post\_2016)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-13-1.pdf}

Here we see a clustering at the bottom of the graph of people who voted
for Hilary Clinton, depicting a general trend of low rankings for the
Alt-right movement, and various feelings towards Christians. As we look
at the yellow clustering towards the very right of the graph, we can see
people who voted for Trump tended to rank their feelings towards
Christians highly, and their opinions towards the Alt-right movement
varied substantially.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(survey, }\FunctionTok{aes}\NormalTok{(ft\_muslim\_2016, ft\_altright\_2016, }\AttributeTok{colour =}\NormalTok{ presvote16post\_2016)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-14-1.pdf}

However when we switch Christians for Muslims, we see a complete
reversal in the opinions of people who voted for Trump. While there is
some cluster near the left of the graph, the feeling thermometers for
Muslims are more varied than Christians for the Trump supporters. For
the people who voted for Clinton, there is the same general trend of low
support for the Alt-right movement, but a general higher ranking for
Muslims than for Christians.

Lastly, let's look at a correlation plot of all of the feeling
thermometers.

\textbf{Correlation Plot}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(corrplot)}
\NormalTok{edited\_survey }\OtherTok{\textless{}{-}}\NormalTok{ survey }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"ft"}\NormalTok{))}
\NormalTok{M }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(edited\_survey)}
\FunctionTok{corrplot}\NormalTok{(M)}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-15-1.pdf}

There are many relationships present as we explore the correlations of
feeling thermometers. Most of the correlations are blue, depicting more
positive correlations than negative. The feeling thermometer with the
most orange/red relationships would be ``ft\_altright\_2016'' or
feelings towards the Alt Right Movement. This makes sense, because the
Alt-right movement traditionally wouldn't pair as well as other groups
might pair together, such as BLM and Feminists. Some of the strongest
associations would be between the feeling thermometers of immigrants
with the feeling thermometers of Hispanics and Muslims. This
relationship would hold, because the United States holds many Hispanic
immigrants and Muslim immigrants, so a positive feeling between the two
groups makes sense.

\hypertarget{data-spliting-model-fitting}{%
\subsection{DATA SPLITING \& MODEL
FITTING}\label{data-spliting-model-fitting}}

To begin fitting our data to appropriate models, I first set a seed and
created a survey training data set and a survey testing data set. I
decided to stratify on `presvote16post\_2016' because this is our
outcome variable, and stratified sampling helps to replicate the same
proportions in each dataset.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{10}\NormalTok{) }\CommentTok{\# setting seed}
\NormalTok{survey\_split }\OtherTok{\textless{}{-}} \FunctionTok{initial\_split}\NormalTok{(survey, }\AttributeTok{prop =} \FloatTok{0.70}\NormalTok{,}
                                \AttributeTok{strata =}\NormalTok{ presvote16post\_2016)}
\NormalTok{survey\_train }\OtherTok{\textless{}{-}} \FunctionTok{training}\NormalTok{(survey\_split)}
\NormalTok{survey\_test }\OtherTok{\textless{}{-}} \FunctionTok{testing}\NormalTok{(survey\_split)}
\end{Highlighting}
\end{Shaded}

Next I created a variable called `survey\_folds' to create divisions of
data (called folds) to test our models on using Cross-Validation.
Cross-validation is a re-sampling method that uses different portions of
the data to test and train a model on different iterations (folds). The
goal of cross-validation is to test the model's ability to predict new
data that was not used in estimating it, in order to flag problems like
over-fitting or selection bias. If we were to use the entire training
set, we would be using the validation set approach where the estimate of
the test MSE is highly variable and is considered a `waste' of data,
because only training data is used to fit the model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey\_folds }\OtherTok{\textless{}{-}} \FunctionTok{vfold\_cv}\NormalTok{(survey\_train, }\AttributeTok{v =} \DecValTok{5}\NormalTok{, }\AttributeTok{strata =}\NormalTok{ presvote16post\_2016)}
\NormalTok{survey\_recipe }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(presvote16post\_2016 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ft\_black\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_white\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_hisp\_2016 }\SpecialCharTok{+} 
\NormalTok{                           ft\_asian\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_muslim\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_jew\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_christ\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_fem\_2016 }\SpecialCharTok{+}
\NormalTok{                          ft\_immig\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_blm\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_wallst\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_gays\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_unions\_2016 }\SpecialCharTok{+}
\NormalTok{                          ft\_police\_2016 }\SpecialCharTok{+}\NormalTok{ ft\_altright\_2016 }\SpecialCharTok{+}\NormalTok{ accurately\_counted2\_2016 }\SpecialCharTok{+}\NormalTok{ alcohol\_2016 }\SpecialCharTok{+} 
\NormalTok{                          smoke100\_2016 }\SpecialCharTok{+}\NormalTok{ pid7\_2016 }\SpecialCharTok{+}\NormalTok{ ideo5\_2016 }\SpecialCharTok{+}\NormalTok{ pew\_religimp\_2016, survey\_train) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_dummy}\NormalTok{(accurately\_counted2\_2016,alcohol\_2016,smoke100\_2016,pid7\_2016,ideo5\_2016,pew\_religimp\_2016) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_normalize}\NormalTok{(}\FunctionTok{all\_predictors}\NormalTok{())}
\CommentTok{\#survey\_recipe \%\textgreater{}\% prep() \%\textgreater{}\% juice()}
\end{Highlighting}
\end{Shaded}

Then I create a singular recipe to use for each of the 5 models I'm
testing. I added in all of the variables listed in the
`survey\_codebook.txt' besides zipcode, time started, and time ended.
With more time in the future I would like to explore those variables,
however I found the other variables easier to work with. I dummy coded
all of the categorical variables and normalized all of the feeling
thermometer numeric data.

As I built each model, I used the same general process:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set up the type of model, engine, and mode to Classification.
\item
  Set up a tuning grid with the specific parameters we want tuned and
  specific levels of tuning.
\item
  Run the Model and select the one with the best roc\_auc, and finalize
  the workflow with tuning parameters.
\item
  Save the model to RDA file to avoid re-runing and save time.
\end{enumerate}

I used roc\_auc as my metric of performance because it calculates the
the area under the curve for the receiver operating characteristic (ROC)
curve, and is a great metric for efficency in a multi-classification
model.

Time for the most important part of the project: building our models. As
previously stated in the introduction, we will be trying out seven
different machine learning techniques all using the same recipe. This
took quite a while because some of the models took multiple hours to run
while they were tuning. The actual model building is a fairly
straightforward process, but it takes up a lot of space, so the code can
be seen in a seperate rmarkdown file if you want to see it. I decided to
set my metric of performance as \textbf{roc\_auc}, because that is what
shows the most significant level of efficiency in a binary
classification model where the data is not perfectly balanced. This
essentially calculates the area under the curve for the receiver
operating characteristic (ROC) curve, which highlights the trade-off
between sensibility and sensitivity. In the end, I think it was a great
success! Nearly every model built had the same process, which I will
detail right now.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set up the type of model, engine, and mode to Classification.
\item
  Set up a tuning grid with the specific parameters we want tuned and
  specific levels of tuning.
\item
  Run the Model and select the one with the best roc\_auc, and finalize
  the workflow with tuning parameters.
\item
  Save the model to RDA file to avoid re-runing and save time.
\end{enumerate}

To see the specific code for each Model, click the code button to the
right!

\hypertarget{model-1-multinomial-logistic-regression}{%
\subsection{MODEL 1 (Multinomial logistic
regression)}\label{model-1-multinomial-logistic-regression}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# logistic regression model using \textquotesingle{}glm\textquotesingle{}}
\NormalTok{reg }\OtherTok{\textless{}{-}} \FunctionTok{multinom\_reg}\NormalTok{(}\AttributeTok{mixture=}\ConstantTok{NULL}\NormalTok{,}\AttributeTok{penalty=}\DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{\textquotesingle{}glmnet\textquotesingle{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{\textquotesingle{}classification\textquotesingle{}}\NormalTok{)}

\CommentTok{\# creating a workflow}
\NormalTok{reg\_wkflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_model}\NormalTok{(reg) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_recipe}\NormalTok{(survey\_recipe)}

\CommentTok{\# fitting workflow w/ training data}
\NormalTok{reg\_fit }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(reg\_wkflow, survey\_train)}

\NormalTok{log\_reg\_acc }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(reg\_fit, }\AttributeTok{new\_data =}\NormalTok{ survey\_train) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{roc\_auc}\NormalTok{(}\AttributeTok{truth =} \StringTok{\textquotesingle{}presvote16post\_2016\textquotesingle{}}\NormalTok{, }\AttributeTok{estimate =} \StringTok{\textasciigrave{}}\AttributeTok{.pred\_Did not vote for President}\StringTok{\textasciigrave{}}\SpecialCharTok{:}\NormalTok{.pred\_Other)}

\CommentTok{\# Cross validation }
\NormalTok{reg\_fold }\OtherTok{\textless{}{-}}\NormalTok{ reg\_wkflow }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{fit\_resamples}\NormalTok{(survey\_folds)}
\NormalTok{collect\_reg }\OtherTok{\textless{}{-}} \FunctionTok{collect\_metrics}\NormalTok{(reg\_fold)}
\NormalTok{log\_reg\_acc\_est }\OtherTok{\textless{}{-}}\NormalTok{ collect\_reg}\SpecialCharTok{$}\NormalTok{mean[}\DecValTok{2}\NormalTok{]}
\CommentTok{\#log\_reg\_acc\_est}
\CommentTok{\#reg\_fold \textless{}{-} fit\_resamples(reg\_wkflow,survey\_folds)}
\CommentTok{\#collect\_reg \textless{}{-} collect\_metrics(reg\_fold)}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-2-regularized-regression-w-elastic-net}{%
\subsection{MODEL 2 (Regularized Regression w/ Elastic
Net)}\label{model-2-regularized-regression-w-elastic-net}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(parsnip)}
\NormalTok{elastic\_net }\OtherTok{\textless{}{-}} \FunctionTok{multinom\_reg}\NormalTok{(}\AttributeTok{penalty =} \FunctionTok{tune}\NormalTok{(),}
                                 \AttributeTok{mixture =} \FunctionTok{tune}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"glmnet"}\NormalTok{)}

\NormalTok{en\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_recipe}\NormalTok{(survey\_recipe) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_model}\NormalTok{(elastic\_net)}

\NormalTok{en\_grid }\OtherTok{\textless{}{-}} \FunctionTok{grid\_regular}\NormalTok{(}\FunctionTok{penalty}\NormalTok{(}\AttributeTok{range =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{)),}
                        \FunctionTok{mixture}\NormalTok{(}\AttributeTok{range =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)), }\AttributeTok{levels =} \DecValTok{10}\NormalTok{)}

\NormalTok{tune\_res }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(en\_workflow,}\AttributeTok{resamples =}\NormalTok{ survey\_folds,}\AttributeTok{grid=}\NormalTok{en\_grid)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{best }\OtherTok{\textless{}{-}} \FunctionTok{select\_best}\NormalTok{(tune\_res,}\AttributeTok{metric=}\StringTok{\textquotesingle{}roc\_auc\textquotesingle{}}\NormalTok{)}
\NormalTok{en\_final }\OtherTok{\textless{}{-}} \FunctionTok{finalize\_workflow}\NormalTok{(en\_workflow,best)}
\NormalTok{en\_final\_fit }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(en\_final, }\AttributeTok{data =}\NormalTok{ survey\_train)}
\NormalTok{predicted }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(en\_final\_fit, }\AttributeTok{new\_data =}\NormalTok{ survey\_test) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(presvote16post\_2016, }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{".pred"}\NormalTok{))  }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{roc\_auc}\NormalTok{(presvote16post\_2016, }\StringTok{\textasciigrave{}}\AttributeTok{.pred\_Did not vote for President}\StringTok{\textasciigrave{}}\SpecialCharTok{:}\NormalTok{.pred\_Other)}
\NormalTok{reg\_reg }\OtherTok{\textless{}{-}}\NormalTok{ predicted}\SpecialCharTok{$}\NormalTok{.estimate}
\CommentTok{\#predicted \#roc\_auc}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-3-decsion-tree}{%
\subsection{MODEL 3 (DECSION TREE)}\label{model-3-decsion-tree}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# setting up decision tree model}
\NormalTok{tree\_spec }\OtherTok{\textless{}{-}} \FunctionTok{decision\_tree}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"rpart"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_args}\NormalTok{(}\AttributeTok{cost\_complexity=}\FunctionTok{tune}\NormalTok{())}

\CommentTok{\#setting up the workflow}
\NormalTok{wrkflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_model}\NormalTok{(tree\_spec) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_recipe}\NormalTok{(survey\_recipe)}

\NormalTok{param\_grid }\OtherTok{\textless{}{-}} \FunctionTok{grid\_regular}\NormalTok{(}\FunctionTok{cost\_complexity}\NormalTok{(}\AttributeTok{range =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)), }\AttributeTok{levels =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tune\_res }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{  wrkflow, }
  \AttributeTok{resamples =}\NormalTok{ survey\_folds, }
  \AttributeTok{grid =}\NormalTok{ param\_grid, }
  \AttributeTok{metrics =} \FunctionTok{metric\_set}\NormalTok{(roc\_auc)}
\NormalTok{)}

\FunctionTok{write\_rds}\NormalTok{(tune\_res, }\AttributeTok{file =} \StringTok{"data/decison{-}tree{-}res.rds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{decision\_tree }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{"data/decison{-}tree{-}res.rds"}\NormalTok{)}
\NormalTok{decision }\OtherTok{\textless{}{-}}\NormalTok{ decision\_tree }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{collect\_metrics}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(mean)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{row\_number}\NormalTok{()}\SpecialCharTok{==}\DecValTok{1}\NormalTok{)}
\NormalTok{decison\_tree\_roc }\OtherTok{\textless{}{-}}\NormalTok{ decision}\SpecialCharTok{$}\NormalTok{mean}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-4-random-forest}{%
\subsection{MODEL 4 (RANDOM FOREST)}\label{model-4-random-forest}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rf }\OtherTok{\textless{}{-}} \FunctionTok{rand\_forest}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{\textquotesingle{}ranger\textquotesingle{}}\NormalTok{,}\AttributeTok{importance=}\StringTok{\textquotesingle{}impurity\textquotesingle{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{\textquotesingle{}classification\textquotesingle{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_args}\NormalTok{(}\AttributeTok{mtry=}\FunctionTok{tune}\NormalTok{(),}\AttributeTok{trees=}\FunctionTok{tune}\NormalTok{(),}\AttributeTok{min\_n=}\FunctionTok{tune}\NormalTok{())}

\NormalTok{rf\_wrkflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_recipe}\NormalTok{(survey\_recipe) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_model}\NormalTok{(rf)}

\NormalTok{rf\_grid }\OtherTok{\textless{}{-}} \FunctionTok{grid\_regular}\NormalTok{(}\FunctionTok{mtry}\NormalTok{(}\AttributeTok{range=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{21}\NormalTok{)), }
                        \FunctionTok{trees}\NormalTok{(}\AttributeTok{range =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{50}\NormalTok{)),}
                        \FunctionTok{min\_n}\NormalTok{(}\AttributeTok{range =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{20}\NormalTok{)),}
                        \AttributeTok{levels =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ranger)}
\NormalTok{tune\_forest }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(rf\_wrkflow, }\AttributeTok{resamples =}\NormalTok{ survey\_folds, }\AttributeTok{grid =}\NormalTok{ rf\_grid, }\AttributeTok{metrics =} \FunctionTok{metric\_set}\NormalTok{(roc\_auc,accruacy))}
\FunctionTok{write\_rds}\NormalTok{(tune\_forest, }\AttributeTok{file =} \StringTok{"data/rand{-}forest{-}res.rsd"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tune\_forest }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{"data/rand{-}forest{-}res.rsd"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rand\_forest\_tuned }\OtherTok{\textless{}{-}}\NormalTok{ tune\_forest }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{collect\_metrics}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(mean)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{row\_number}\NormalTok{()}\SpecialCharTok{==}\DecValTok{1}\NormalTok{)}
\NormalTok{rf\_mean }\OtherTok{\textless{}{-}}\NormalTok{ rand\_forest\_tuned}\SpecialCharTok{$}\NormalTok{mean}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-5-boosted-tree}{%
\subsection{MODEL 5 (BOOSTED TREE)}\label{model-5-boosted-tree}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(xgboost)}
\NormalTok{boasted\_tree }\OtherTok{\textless{}{-}} \FunctionTok{boost\_tree}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{\textquotesingle{}xgboost\textquotesingle{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{\textquotesingle{}classification\textquotesingle{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_args}\NormalTok{(}\AttributeTok{trees=}\FunctionTok{tune}\NormalTok{())}

\NormalTok{boasted\_wrkflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_recipe}\NormalTok{(survey\_recipe) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_model}\NormalTok{(boasted\_tree)}

\NormalTok{boasted\_grid }\OtherTok{\textless{}{-}} \FunctionTok{grid\_regular}\NormalTok{(}\FunctionTok{trees}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{2000}\NormalTok{)), }\AttributeTok{levels =} \DecValTok{10}\NormalTok{)}

\NormalTok{boasted\_tune\_res }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(boasted\_wrkflow, }\AttributeTok{resamples=}\NormalTok{survey\_folds, }\AttributeTok{grid =}\NormalTok{ boasted\_grid, }\AttributeTok{metrics =} \FunctionTok{metric\_set}\NormalTok{(roc\_auc))}

\FunctionTok{write\_rds}\NormalTok{(boasted\_tune\_res, }\AttributeTok{file =} \StringTok{"data/boasted\_tune\_res.rsd"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boasted\_tune\_res }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\AttributeTok{file =} \StringTok{"data/boasted\_tune\_res.rsd"}\NormalTok{)}
\NormalTok{boasted }\OtherTok{\textless{}{-}}\NormalTok{ boasted\_tune\_res }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{collect\_metrics}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(mean)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{row\_number}\NormalTok{()}\SpecialCharTok{==}\DecValTok{1}\NormalTok{)}
\NormalTok{boasted\_mean }\OtherTok{\textless{}{-}}\NormalTok{ boasted}\SpecialCharTok{$}\NormalTok{mean}
\end{Highlighting}
\end{Shaded}

\hypertarget{summary-of-models}{%
\subsection{SUMMARY OF MODELS}\label{summary-of-models}}

I decided to evaluate my models based on the roc\_auc score (as
explained above), and here we see that Regularized Regression w/ an
Elastic Net won! However the margins were very close, and all of the
models did pretty well.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roc\_auc }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(log\_reg\_acc\_est,reg\_reg,decison\_tree\_roc,rf\_mean,boasted\_mean)}
\NormalTok{models }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Multinomial Regression"}\NormalTok{, }\StringTok{"Regularized Regression (Elastic Net)"}\NormalTok{,}\StringTok{"Decsion Tree"}\NormalTok{, }\StringTok{"Random Forest"}\NormalTok{,}\StringTok{"Boasted Tree"}\NormalTok{)}
\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{models=}\NormalTok{models,}\AttributeTok{roc\_auc=}\NormalTok{ roc\_auc)}
\NormalTok{results }\OtherTok{\textless{}{-}}\NormalTok{ results }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{roc\_auc)}
\NormalTok{results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 2
##   models                               roc_auc
##   <chr>                                  <dbl>
## 1 Regularized Regression (Elastic Net)   0.766
## 2 Multinomial Regression                 0.758
## 3 Random Forest                          0.749
## 4 Boasted Tree                           0.727
## 5 Decsion Tree                           0.688
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modesl\_bar\_plot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(results, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ models, }\AttributeTok{y =}\NormalTok{ roc\_auc)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{width=}\FloatTok{0.2}\NormalTok{, }\AttributeTok{fill =} \StringTok{"pink"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }

\NormalTok{models\_lollipop\_plot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(results, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ models, }\AttributeTok{y =}\NormalTok{ roc\_auc)) }\SpecialCharTok{+} 
    \FunctionTok{geom\_segment}\NormalTok{( }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{models, }\AttributeTok{xend =} \DecValTok{0}\NormalTok{, }\AttributeTok{y =}\NormalTok{ roc\_auc, }\AttributeTok{yend =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{( }\AttributeTok{size=}\DecValTok{7}\NormalTok{, }\AttributeTok{color=} \StringTok{"black"}\NormalTok{, }\AttributeTok{fill=}\FunctionTok{alpha}\NormalTok{(}\StringTok{"\#FB4F14"}\NormalTok{, }\FloatTok{0.3}\NormalTok{), }\AttributeTok{alpha=}\FloatTok{0.7}\NormalTok{, }\AttributeTok{shape=}\DecValTok{21}\NormalTok{, }\AttributeTok{stroke=}\DecValTok{3}\NormalTok{)}
\NormalTok{modesl\_bar\_plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-31-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{models\_lollipop\_plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-31-2.pdf}

\textbf{Let's fit the best model to our training/testing data}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prediction\_accuracy }\OtherTok{\textless{}{-}} \FunctionTok{bind\_cols}\NormalTok{(}\FunctionTok{predict}\NormalTok{(en\_final\_fit, survey\_train, }\AttributeTok{type=}\StringTok{\textquotesingle{}prob\textquotesingle{}}\NormalTok{))}
\NormalTok{prediction\_accuracy\_test\_acc }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(en\_final\_fit, }\AttributeTok{new\_data =}\NormalTok{ survey\_train) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{accuracy}\NormalTok{(}\AttributeTok{truth =} \StringTok{\textquotesingle{}presvote16post\_2016\textquotesingle{}}\NormalTok{, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\NormalTok{prediction\_accuracy\_test\_acc }\CommentTok{\# testing accuracy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##   .metric  .estimator .estimate
##   <chr>    <chr>          <dbl>
## 1 accuracy multiclass     0.885
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prediction }\OtherTok{\textless{}{-}} \FunctionTok{bind\_cols}\NormalTok{(}\FunctionTok{predict}\NormalTok{(en\_final\_fit, survey\_test, }\AttributeTok{type=}\StringTok{\textquotesingle{}prob\textquotesingle{}}\NormalTok{))}
\NormalTok{test\_acc }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(en\_final\_fit, }\AttributeTok{new\_data =}\NormalTok{ survey\_test) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{accuracy}\NormalTok{(}\AttributeTok{truth =} \StringTok{\textquotesingle{}presvote16post\_2016\textquotesingle{}}\NormalTok{, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\NormalTok{test\_acc }\CommentTok{\# testing accuracy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##   .metric  .estimator .estimate
##   <chr>    <chr>          <dbl>
## 1 accuracy multiclass     0.877
\end{verbatim}

Here we can see the our Regularized Regression w/ an Elastic Net has an
accuracy rating of 0.8845938 on the survey training data, and an
0.8766319 accuracy rating on the survey testing data. This is fairly
high, and a really great result. A potential reason for the higher
rating on the training data could be over fitting, which is common in
training data sets.

\hypertarget{misc-visualizations}{%
\subsection{MISC Visualizations}\label{misc-visualizations}}

Here are some interesting Visualizations from our models!

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{augment}\NormalTok{(en\_final\_fit, }\AttributeTok{new\_data =}\NormalTok{ survey\_test) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{conf\_mat}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ presvote16post\_2016, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)  }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{(}\AttributeTok{type=}\StringTok{\textquotesingle{}heatmap\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-34-1.pdf}

This is a heat map for the Regularized Regression w/ an Elastic Net. A
heat map shows the amount of correct/incorrect guesses by the model, and
can also be described as a false color image. Th results here tell me
that the model incorrectly guessed on the darker boxes, however these
are small numbers compared to the size of the dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rand\_forest }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\AttributeTok{file =} \StringTok{"data/rand{-}forest{-}res.rsd"}\NormalTok{)}
\NormalTok{rand\_forest }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-35-1.pdf}

For our random forest model we tuned three different parameters: mtry -
the number of predictors that would be randomly sampled, trees - the
number of trees to grow in the forest, and min\_n - the minimum number
of data values needed to create another split. However it doesn't seem
that as the number of predictors had a strong positive effect on the
accuracy. It does look like as the number of trees increased, the ROC
AUC also increased. The most optimal model was around 37 trees at a node
size of 15 with a very low number of predictors.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Random Forest}
\NormalTok{best\_rf }\OtherTok{\textless{}{-}} \FunctionTok{select\_best}\NormalTok{(rand\_forest, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\NormalTok{rf\_final }\OtherTok{\textless{}{-}} \FunctionTok{finalize\_workflow}\NormalTok{(rf\_wrkflow, best\_rf)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\NormalTok{class\_tree\_final\_fit }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(rf\_final, }\AttributeTok{data =}\NormalTok{ survey\_train)}
\NormalTok{class\_tree\_final\_fit }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{extract\_fit\_engine}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{vip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-36-1.pdf}

This is a very descriptive and unique plot, especially with the data we
are working with. Here we can see that for our Random Forest Model the
most important variable when determining who someone would vote for was
``ft\_blm\_2016'' or how they ranked Black Lives Matter. The Second Most
important variable was how one ranked ``ft\_fem\_2016''or how they
ranked Feminists. I think these two determinations make sense, because
both Democrats and Republicans feel very different about the two groups.
It's interesting to me though because both of these factors were more
important than how someone ranked themselves ideologically (liberal to
conservative), and I would have thought that would be more telling to
the model.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# BOASTING}
\NormalTok{boasted\_tune\_res }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\AttributeTok{file =} \StringTok{"data/boasted\_tune\_res.rsd"}\NormalTok{)}
\NormalTok{boasted\_tune\_res }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-37-1.pdf}

Here we can see with our Boasting Tree Model that the best number of
trees was just below 250.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{decision\_tree }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{"data/decison{-}tree{-}res.rds"}\NormalTok{)}
\FunctionTok{autoplot}\NormalTok{(decision\_tree)}
\end{Highlighting}
\end{Shaded}

\includegraphics{final_draft_files/figure-latex/unnamed-chunk-38-1.pdf}

The cost complexity parameter is used to control the size of the
decision tree and to select the optimal tree size. Here we can see a
sharp decline in roc\_auc as our cost-complexity parameter increases,
depicting a high cost of adding variables to the decision tree from the
current node.

\hypertarget{conclusion}{%
\subsection{CONCLUSION}\label{conclusion}}

We set out to determine if we could predict how a person voted in the
2016 presidential election if given someone's party affiliation or
political values. We also wanted to predict which would be more
important in determining who they voted for.

From the data from our Random Forest, we found that the two most
important variables in determining the way one would vote in the 2016
election were how they ranked BLM and how they ranked Feminists. I think
this is particularly interesting because respondents also stated their
party affiliation/leanings, yet this was not as important. If it was
already not apparent, the data here suggests that those two groups are
the most polarizing within all of the feeling thermometer variables.
Additionally, although our EDA graphs show clear contrasts between
voting groups, none of the ethnic groups show up as particularity
polarizing besides Muslim.

While all of our Models had similar and high roc\_auc ratings,
Regularized Regression w/ an Elastic Net performed the best. When tested
on the survey training and testing data set, the model recorded an
accuracy rating of 88\% and 87\%, respectively. I think that this is
out-standing, given that we are working off of survey data. This model
might be the most best because of it's complexity in combining the
penalties of ridge regression and lasso ``to get the best of both
worlds'' (Oleszak).

Overall this was a really interesting project, and I'm really grateful
for the exposure to such high level concepts and the opportunity to
explore themes really important to me.

Thank you for reading through!

\hypertarget{citations}{%
\subsection{CITATIONS}\label{citations}}

Nadeem, Reem. ``In a Politically Polarized Era, Sharp Divides in Both
Partisan Coalitions.'' Pew Research Center - U.S. Politics \& Policy,
Pew Research Center, 30 May 2020,
\url{https://www.pewresearch.org/politics/2019/12/17/in-a-politically-polarized-era-sharp-divides-in-both-partisan-coalitions/}.

Oleszak, Michał ``Regularization Tutorial: Ridge, Lasso \& Elastic Net
Regression.'' \emph{DataCamp}, DataCamp, 12 Nov.~2019,
\url{https://www.datacamp.com/tutorial/tutorial-ridge-lasso-elastic-net.}

Democracy Fund Voter Study Group. VIEWS OF THE ELECTORATE RESEARCH
SURVEY, December 2016. {[}Computer File{]} Release 1: August 28, 2017.
Washington DC: Democracy Fund Voter Study Group {[}producer{]}
\url{https://www.voterstudygroup.org/}.

\end{document}
